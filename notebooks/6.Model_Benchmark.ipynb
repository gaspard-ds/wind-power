{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from amlbench.benchmark.interface import Benchmark, Method, FeatureSpace\n",
    "from amlbench.benchmark.benchmark_engine import BenchmarkEngine\n",
    "from amlbench.benchmark.experiment_reports import get_reports_df\n",
    "from amlbench.benchmark.split_strategies import LastDaysOfMonthSplit, TimePivotSplit\n",
    "from amlbench.benchmark.project_folders import create_paths\n",
    "from amlbench.benchmark.metric import Metric, METRIC_R2, METRIC_CVRMSE\n",
    "from amlbench.benchmark.results_plots import (\n",
    "    display_all_plots,\n",
    "    display_bar_plot,\n",
    "    display_box_plots,\n",
    ")\n",
    "from amlbench.benchmark.method_space import method_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, LarsCV\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fixing the random seed\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")  # append parent dir to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wind_constants as cst\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(cst.params)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 1500)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load(\"../data/processed/processed_uncleaned.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models to benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the method object, you can choose to input any model and split_strategy\n",
    "\n",
    "methods = method_space(\n",
    "    model=[\n",
    "        LinearRegression(normalize=True),\n",
    "        LassoCV(normalize=True),\n",
    "        RandomForestRegressor(),\n",
    "        AdaBoostRegressor(),\n",
    "        LarsCV(normalize=True),\n",
    "        ExtraTreesRegressor(),\n",
    "        GradientBoostingRegressor(),\n",
    "    ],\n",
    "    split_strategy=[TimePivotSplit(), TimePivotSplit(pivot_quantile=0.5),],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target (for relative production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = FeatureSpace(name=\"all\", features=cst.FEATURES, methods=methods)\n",
    "reduced = FeatureSpace(name=\"reduced\", features=cst.FEATURES_REDUCED, methods=methods)\n",
    "national_average = FeatureSpace(\n",
    "    name=\"national\", features=cst.FEATURES_GLOBAL, methods=methods\n",
    ")\n",
    "benchmark = Benchmark(feature_spaces=[feature_space, reduced], target=cst.TARGET,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target (for total production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_features = FeatureSpace(\n",
    "    name=\"alternative\",\n",
    "    features=cst.ALT_FEATURES,\n",
    "    methods=Method(model=LinearRegression(normalize=True), name=\"lr\"),\n",
    ")\n",
    "alt_benchmark = Benchmark(feature_spaces=alt_features, target=cst.ALT_TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ProjectFolders instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to store data, models and reports\n",
    "\n",
    "project_folders = create_paths(\n",
    "    data_path=Path(\"../data\"),\n",
    "    models_path=Path(\"../models\"),\n",
    "    reports_path=Path(\"../reports\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = METRIC_R2\n",
    "R2.cross_validation = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing and fitting benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bench = BenchmarkEngine(\n",
    "    project_folders=project_folders,\n",
    "    benchmarks=[benchmark, alt_benchmark],\n",
    "    metrics=[R2, METRIC_CVRMSE],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiments:  55%|█████▌    | 16/29 [03:55<01:38,  7.56s/it]"
     ]
    }
   ],
   "source": [
    "# In order to fit the Benchmark on several cores, it is possible to input the keyword argument n_jobs (by default at 1, disabling any parallelization)\n",
    "\n",
    "my_bench = my_bench.fit(data=data, n_jobs=4, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_reports_df(experiments=my_bench.experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"List of features\",\n",
    "        \"Pre-Split Transformation\",\n",
    "        \"Post-Split Transformation\",\n",
    "        \"Feature Selection\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"R² Test\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bar_plot(input_df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_box_plots(input_df=df, method_attributes=[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_box_plots(input_df=df, metric_name=\"CVRMSE\", method_attributes=[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bench.experiments[0].predict(data[cst.FEATURES].dropna()).plot(\n",
    "    label=\"Linear Regression Predictions\"\n",
    ")\n",
    "data[cst.TARGET].plot(label=\"Target\")\n",
    "plt.legend()\n",
    "plt.title(\n",
    "    \"Comparaison of target and (LR) predictions over the whole period (train+test)\"\n",
    ")\n",
    "plt.ylabel(\"Relative Production (MW/MW_installed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    my_bench.experiments[0].predict(data[cst.FEATURES].dropna()) * data[\"capacity\"] * 6\n",
    ").truncate(before=\"2018-09-11 08:00:00+02:00\").resample(\"D\").sum().plot(\n",
    "    label=\"LR Predictions - with relative power\"\n",
    ")\n",
    "\n",
    "data[\"production\"].truncate(before=\"2018-09-11 08:00:00+02:00\").resample(\n",
    "    \"D\"\n",
    ").sum().plot(label=\"Production - over 3H - (MWH)\")\n",
    "\n",
    "(my_bench.experiments[28].predict(data[cst.ALT_FEATURES].dropna())).truncate(\n",
    "    before=\"2018-09-11 08:00:00+02:00\"\n",
    ").resample(\"D\").sum().plot(label=\"LR Predictions - with absolute power\")\n",
    "plt.legend()\n",
    "plt.title(\n",
    "    \"Comparaison of daily target and both predictions methods over the whole period (test only)\"\n",
    ")\n",
    "plt.ylabel(\"Absolute Production (MWH)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    my_bench.experiments[0].predict(data[cst.FEATURES].dropna()) * data[\"capacity\"] * 6\n",
    ").resample(\"W\").sum().plot(label=\"LR Predictions - with relative power\")\n",
    "data[\"production\"].resample(\"W\").sum().plot(label=\"Production - over 3H - (MWh)\")\n",
    "(my_bench.experiments[28].predict(data[cst.ALT_FEATURES].dropna())).resample(\n",
    "    \"W\"\n",
    ").sum().plot(label=\"LR Predictions - with absolute power\")\n",
    "plt.title(\n",
    "    \"Comparaison of weekly target and both predictions methods over the whole period (train+test)\"\n",
    ")\n",
    "plt.axvline(\"2018-09-11 08:00:00+02:00\", c=\"black\", label=\"Train/Test split\")\n",
    "plt.ylabel(\"Absolute Production (MWh)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[\"model_prediction_LR\"] = my_bench.experiments[0].predict(\n",
    "    data[cst.FEATURES].dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[\"model_prediction_extra_trees\"] = my_bench.experiments[15].predict(\n",
    "    data[cst.FEATURES].dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[\"target\"] = data[cst.TARGET].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred[\"model_prediction_extra_trees\"], pred[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data[cst.FEATURES + [\"capacity\"] + [cst.TARGET] + [cst.ALT_TARGET]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(30, 30))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    "    annot=True,\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amlbench",
   "language": "python",
   "name": "amlbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
